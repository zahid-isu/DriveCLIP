{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "53N4k0pj_9qL"
      },
      "source": [
        "# Preparation for Colab\n",
        "\n",
        "Make sure you're running a GPU runtime; if not, select \"GPU\" as the hardware accelerator in Runtime > Change Runtime Type in the menu. The next cells will install the `clip` package and its dependencies, and check if PyTorch 1.7.1 or later is installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zero_samdd.ipynb  zero_shot_demoSF.ipynb\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BpdJkdBssk9",
        "outputId": "41a4070f-5321-4fc4-bd4d-0b5c1f476d56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ftfy in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (6.1.1)\n",
            "Requirement already satisfied: regex in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (4.65.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from ftfy) (0.2.6)\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-tdxw0tnm\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-tdxw0tnm\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: ftfy in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from clip==1.0) (6.1.1)\n",
            "Requirement already satisfied: regex in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from clip==1.0) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from clip==1.0) (4.65.0)\n",
            "Requirement already satisfied: torch in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from clip==1.0) (2.0.1)\n",
            "Requirement already satisfied: torchvision in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from clip==1.0) (0.15.2)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from ftfy->clip==1.0) (0.2.6)\n",
            "Requirement already satisfied: filelock in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torch->clip==1.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torch->clip==1.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torch->clip==1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torch->clip==1.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torch->clip==1.0) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torch->clip==1.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torch->clip==1.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torch->clip==1.0) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torch->clip==1.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torch->clip==1.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torch->clip==1.0) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torch->clip==1.0) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torch->clip==1.0) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torch->clip==1.0) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torch->clip==1.0) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torch->clip==1.0) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torch->clip==1.0) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->clip==1.0) (68.0.0)\n",
            "Requirement already satisfied: wheel in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->clip==1.0) (0.38.4)\n",
            "Requirement already satisfied: cmake in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from triton==2.0.0->torch->clip==1.0) (3.26.4)\n",
            "Requirement already satisfied: lit in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from triton==2.0.0->torch->clip==1.0) (16.0.6)\n",
            "Requirement already satisfied: numpy in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torchvision->clip==1.0) (1.25.0)\n",
            "Requirement already satisfied: requests in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torchvision->clip==1.0) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from torchvision->clip==1.0) (10.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from jinja2->torch->clip==1.0) (2.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from requests->torchvision->clip==1.0) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from requests->torchvision->clip==1.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from requests->torchvision->clip==1.0) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from requests->torchvision->clip==1.0) (2023.5.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/zahid/.conda/envs/clip/lib/python3.9/site-packages (from sympy->torch->clip==1.0) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install ftfy regex tqdm\n",
        "! pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1hkDT38hSaP",
        "outputId": "e10d4f17-8fa6-4b75-a18f-f0c38990b5a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch version: 2.0.1+cu117\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import clip\n",
        "from tqdm.notebook import tqdm\n",
        "from pkg_resources import packaging\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eFxgLV5HAEEw"
      },
      "source": [
        "# Loading the model\n",
        "\n",
        "Download and instantiate a CLIP model using the `clip` module that we just installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLFS29hnhlY4",
        "outputId": "09abb234-693e-4efb-953f-e1847ba95758"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['RN50',\n",
              " 'RN101',\n",
              " 'RN50x4',\n",
              " 'RN50x16',\n",
              " 'RN50x64',\n",
              " 'ViT-B/32',\n",
              " 'ViT-B/16',\n",
              " 'ViT-L/14',\n",
              " 'ViT-L/14@336px']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clip.available_models()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SAM-DD dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running zero-shot on ViT-L/14:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Subjects: 100%|██████████| 14/14 [00:00<00:00, 337.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in the dataset: 14336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 14.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 768, 10])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/448 [00:00<?, ?it/s]/tmp/ipykernel_821972/3774060225.py:99: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  return [float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy()) for k in topk]\n",
            "100%|██████████| 448/448 [02:30<00:00,  2.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 accuracy_ViT-L/14: 62.51%\n",
            "Top-3 accuracy_ViT-L/14: 84.52%\n",
            "Running zero-shot on ViT-L/14@336px:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 891M/891M [00:18<00:00, 49.2MiB/s]\n",
            "Subjects: 100%|██████████| 14/14 [00:00<00:00, 310.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in the dataset: 14336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 59.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 768, 10])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 448/448 [03:06<00:00,  2.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 accuracy_ViT-L/14@336px: 66.52%\n",
            "Top-3 accuracy_ViT-L/14@336px: 86.33%\n",
            "Running zero-shot on ViT-B/16:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Subjects: 100%|██████████| 14/14 [00:00<00:00, 279.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in the dataset: 14336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 60.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512, 10])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 448/448 [02:37<00:00,  2.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 accuracy_ViT-B/16: 18.67%\n",
            "Top-3 accuracy_ViT-B/16: 79.18%\n",
            "Running zero-shot on ViT-B/32:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Subjects: 100%|██████████| 14/14 [00:00<00:00, 267.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in the dataset: 14336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 57.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512, 10])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 448/448 [02:44<00:00,  2.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 accuracy_ViT-B/32: 10.48%\n",
            "Top-3 accuracy_ViT-B/32: 40.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Run zero-shotCLIP model on SAM-DD valid dataset\n",
        "import torch\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import clip\n",
        "import os\n",
        "\n",
        "# Load CLIP models\n",
        "model_list= ['ViT-L/14', 'ViT-L/14@336px', 'ViT-B/16', 'ViT-B/32']\n",
        "for model_ in model_list:\n",
        "    print(f\"Running zero-shot on {model_}:\")\n",
        "    model, preprocess = clip.load(f\"{model_}\", device='cuda')\n",
        "\n",
        "    # Define the image extensions\n",
        "    def is_image_file(filename):\n",
        "        valid_image_extensions = [\".jpg\", \".jpeg\", \".png\"]\n",
        "        return any(filename.lower().endswith(ext) for ext in valid_image_extensions)\n",
        "\n",
        "    class CustomImageFolder(ImageFolder):\n",
        "        def __init__(self, root, transform=None, is_valid_file=None):\n",
        "            self.is_valid_file = is_valid_file or is_image_file\n",
        "            super(CustomImageFolder, self).__init__(root, transform=transform, is_valid_file=self.is_valid_file)\n",
        "            self.samples = self.make_dataset_with_camera_views(self.root, is_valid_file=self.is_valid_file)\n",
        "        \n",
        "        def make_dataset_with_camera_views(self, dir, is_valid_file=None):\n",
        "            instances = []\n",
        "            dir = os.path.expanduser(dir)\n",
        "            \n",
        "            # Iterate through each subject directory\n",
        "            for subject_dir in tqdm(sorted(os.listdir(dir)), desc='Subjects'):\n",
        "                subject_path = os.path.join(dir, subject_dir)\n",
        "                if not os.path.isdir(subject_path):\n",
        "                    continue\n",
        "                # create class_to_idx inside the method\n",
        "                class_to_idx = {d: i for i, d in enumerate(sorted(os.listdir(subject_path)))}\n",
        "                \n",
        "                # Iterate through each class directory\n",
        "                for class_name in sorted(class_to_idx.keys()):\n",
        "                    class_index = class_to_idx[class_name]\n",
        "                    class_dir = os.path.join(subject_path, class_name)\n",
        "                    camera_angle_dir = os.path.join(class_dir, \"side_RGB\")  # Only using the \"front_RGB\" folder\n",
        "                    \n",
        "                    if os.path.isdir(camera_angle_dir):\n",
        "                        for root, _, fnames in os.walk(camera_angle_dir):\n",
        "                            for fname in fnames:\n",
        "                                if is_valid_file(fname):\n",
        "                                    path = os.path.join(root, fname)\n",
        "                                    instances.append((path, class_index))\n",
        "            return instances\n",
        "        \n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            img, label = super().__getitem__(index)\n",
        "            path = self.samples[index][0]\n",
        "            return img, label, path\n",
        "\n",
        "    val_data_dir = f\"../sam-dd/valid\"\n",
        "    val_dataset = CustomImageFolder(val_data_dir, transform=preprocess)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "    print(f\"Number of samples in the dataset: {len(val_dataset)}\")\n",
        "\n",
        "    # Assume class_names are defined as per your dataset classes\n",
        "    class_names = [ \"driving safely\", \n",
        "                    \"drinking water while driving\",\n",
        "                    \"talking to the phone on left hand while driving\",\n",
        "                    \"talking to the phone on right hand while driving\",\n",
        "                    \"texting on the phone with left hand while driving\",\n",
        "                    \"texting on the phone with right hand while driving\",\n",
        "                    \"touching hairs with hand while driving\",\n",
        "                    \"adjusting glasses with hand while driving\",\n",
        "                    \"reaching behind while driving\",\n",
        "                    \"dropping the head while driving\"]\n",
        "    templates = [\"an image of a person {}.\"]\n",
        "\n",
        "    # Function for zero-shot prediction\n",
        "    def zeroshot_classifier(classnames, templates):\n",
        "        with torch.no_grad():\n",
        "            zeroshot_weights = []\n",
        "            for classname in tqdm(classnames):\n",
        "                texts = [template.format(classname) for template in templates] #format with class\n",
        "                texts = clip.tokenize(texts).cuda() #tokenize\n",
        "                class_embeddings = model.encode_text(texts) #embed with text encoder\n",
        "                class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
        "                # class_embedding = class_embeddings.mean(dim=0)\n",
        "                # class_embedding /= class_embedding.norm()\n",
        "                class_embedding = class_embeddings\n",
        "                zeroshot_weights.append(class_embedding)\n",
        "            zeroshot_weights = torch.stack(zeroshot_weights, dim=2).cuda()\n",
        "        return zeroshot_weights\n",
        "\n",
        "    zeroshot_weights = zeroshot_classifier(class_names, templates)\n",
        "\n",
        "    print(zeroshot_weights.shape)\n",
        "    # Perform zero-shot prediction\n",
        "    def accuracy(output, target, topk=(1,)):\n",
        "        pred = output.topk(max(topk), 1, True, True)[1].t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "        return [float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy()) for k in topk]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        top1, top3, n = 0., 0., 0.\n",
        "        for images, target, _ in tqdm(val_loader):\n",
        "            images = images.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "            # Predict\n",
        "            image_features = model.encode_image(images)\n",
        "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "            logits = image_features @ zeroshot_weights\n",
        "            logits = logits.squeeze(0)  # Removing the first singleton dimension\n",
        "\n",
        "            # Measure accuracy\n",
        "            acc1, acc3 = accuracy(logits, target, topk=(1, 3))\n",
        "            top1 += acc1\n",
        "            top3 += acc3\n",
        "            n += images.size(0)\n",
        "\n",
        "    # Calculate and print the top-1 and top-5 accuracy\n",
        "    top1 = (top1 / n) * 100\n",
        "    top3 = (top3 / n) * 100\n",
        "    print(f\"Top-1 accuracy_{model_}: {top1:.2f}%\")\n",
        "    print(f\"Top-3 accuracy_{model_}: {top3:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Prompt Engineering for ImageNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "085d5388abda4202bfa66d0c088452f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "179b8ae1eb7f4a828f953e889b141725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "392656f01b2945f3bd7903783ed8cc96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "412dd15f0d8542f5ab2730f8616fb582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f75124b64aa147c693c67a78f8e3a231",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_085d5388abda4202bfa66d0c088452f8",
            "value": 1000
          }
        },
        "41b1ed6b0a9745c1a595377670b15ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8764308b948745f1a677332fd21fcaf0",
            "placeholder": "​",
            "style": "IPY_MODEL_800e30f5b4f24475a2b0046da0703631",
            "value": " 313/313 [02:31&lt;00:00,  2.07it/s]"
          }
        },
        "5e6315f36b4e4eeea5c6294b024e0c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc6d1416c01a4047935ee15c3fd2eb1c",
            "placeholder": "​",
            "style": "IPY_MODEL_6e5676a054874243b55fc6d120a07d01",
            "value": " 1000/1000 [16:51&lt;00:00,  1.01s/it]"
          }
        },
        "610b775178c645e2b4663b77cc0c67b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a1639713ae441d8a9b873381f9d774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_412dd15f0d8542f5ab2730f8616fb582",
              "IPY_MODEL_5e6315f36b4e4eeea5c6294b024e0c97"
            ],
            "layout": "IPY_MODEL_610b775178c645e2b4663b77cc0c67b6"
          }
        },
        "6e5676a054874243b55fc6d120a07d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "800e30f5b4f24475a2b0046da0703631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84f80a7f3e764346969a347b0f71b24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e47a435519b4ce090879b4be2f61f99",
              "IPY_MODEL_41b1ed6b0a9745c1a595377670b15ff4"
            ],
            "layout": "IPY_MODEL_392656f01b2945f3bd7903783ed8cc96"
          }
        },
        "8764308b948745f1a677332fd21fcaf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e47a435519b4ce090879b4be2f61f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8708e8414fd44f4abd6590c9b57996f",
            "max": 313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_179b8ae1eb7f4a828f953e889b141725",
            "value": 313
          }
        },
        "d8708e8414fd44f4abd6590c9b57996f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc6d1416c01a4047935ee15c3fd2eb1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f75124b64aa147c693c67a78f8e3a231": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
